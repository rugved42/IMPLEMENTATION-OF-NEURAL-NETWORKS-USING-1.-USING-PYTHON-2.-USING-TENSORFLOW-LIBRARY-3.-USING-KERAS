{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hidden layer neural network. Code from scratch\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X, y = fetch_openml('Fashion-MNIST', version=1, return_X_y=True)\n",
    "X = X / 255\n",
    "\n",
    "digits = 10\n",
    "points = y.shape[0]\n",
    "print(points)\n",
    "\n",
    "y = y.reshape(1, points)\n",
    "\n",
    "Y_new = np.eye(digits)[y.astype('int32')]\n",
    "Y_new = Y_new.T.reshape(digits, points)\n",
    "\n",
    "maxi = 60000\n",
    "max_t = X.shape[0] - maxi\n",
    "\n",
    "X_train, X_test = X[:maxi].T, X[maxi:].T\n",
    "Y_train, Y_test = Y_new[:,:maxi], Y_new[:,maxi:]\n",
    "\n",
    "shuffle_index = np.random.permutation(maxi)\n",
    "X_train, Y_train = X_train[:, shuffle_index], Y_train[:, shuffle_index]\n",
    "\n",
    "i = 12\n",
    "plt.imshow(X_train[:,i].reshape(28,28), cmap = matplotlib.cm.binary)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "print(Y_train[:,i])\n",
    "\n",
    "def cross_entropy_loss(Y, Y_hat):\n",
    "\n",
    "    L_sum = np.sum(np.multiply(Y, np.log(Y_hat)))\n",
    "    m = Y.shape[1]\n",
    "    L = -(1/m) * L_sum\n",
    "\n",
    "    return L\n",
    "\n",
    "def sigmoid(z):\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    return s\n",
    "\n",
    "num_x = X_train.shape[0]\n",
    "num_h = 64\n",
    "learning_rate = 0.5\n",
    "\n",
    "W1 = np.random.randn(num_h, num_x)\n",
    "b1 = np.zeros((num_h, 1))\n",
    "W2 = np.random.randn(digits, num_h)\n",
    "b2 = np.zeros((digits, 1))\n",
    "\n",
    "X = X_train\n",
    "Y = Y_train\n",
    "\n",
    "losstrack = list()\n",
    "\n",
    "for i in range(1000):\n",
    "\n",
    "    Z1 = np.matmul(W1,X) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.matmul(W2,A1) + b2\n",
    "    A2 = np.exp(Z2) / np.sum(np.exp(Z2), axis=0)\n",
    "\n",
    "    cost = cross_entropy_loss(Y, A2)\n",
    "    losstrack.append(np.squeeze(cost))\n",
    "\n",
    "    dZ2 = A2-Y\n",
    "    dW2 = (1./maxi) * np.matmul(dZ2, A1.T)\n",
    "    db2 = (1./maxi) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "    dA1 = np.matmul(W2.T, dZ2)\n",
    "    dZ1 = dA1 * sigmoid(Z1) * (1 - sigmoid(Z1))\n",
    "    dW1 = (1./maxi) * np.matmul(dZ1, X.T)\n",
    "    db1 = (1./maxi) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "\n",
    "    if (i % 100 == 0):\n",
    "        print(\"Epoch\", i, \"cost: \", cost)\n",
    "\n",
    "print(\"Final cost:\", cost)\n",
    "\n",
    "plt.plot(losstrack)\n",
    "plt.show()\n",
    "\n",
    "Z1 = np.matmul(W1, X_test) + b1\n",
    "A1 = sigmoid(Z1)\n",
    "Z2 = np.matmul(W2, A1) + b2\n",
    "A2 = np.exp(Z2) / np.sum(np.exp(Z2), axis=0)\n",
    "\n",
    "predictions = np.argmax(A2, axis=0)\n",
    "labels = np.argmax(Y_test, axis=0)\n",
    "predictions = np.argmax(A2, axis=0)\n",
    "labels = np.argmax(Y_test, axis=0)\n",
    "\n",
    "print(confusion_matrix(predictions, labels))\n",
    "print(classification_report(predictions, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN Using Tensorflow. \n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model_1 = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(256, activation=tf.nn.tanh),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model_1.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#model.fit(x_train, y_train, epochs=2)\n",
    "history = model_1.fit(x_train, y_train, epochs=15)\n",
    "plt.plot(history.history['loss'])\n",
    "\n",
    "test_predictions = model_1.predict(x_test)\n",
    "\n",
    "print(y_test.shape)\n",
    "print(x_test.shape)\n",
    "# Compute confusion matrix\n",
    "#confusion = tf.confusion_matrix(y_test, test_predictions)\n",
    "test_predictions = model_1.predict_classes(x_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_true = y_test, y_pred = test_predictions)\n",
    "print(confusion_matrix)\n",
    "print(classification_report(y_true = y_test, y_pred = test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN Using Keras with one hidden layer of 64 Nodes. \n",
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "(X_train,Y_train), (X_test,Y_test) = fashion_mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(-1, 28,28, 1)\n",
    "X_test = X_test.reshape(-1, 28,28, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "Y_train_t_h = to_categorical(Y_train)\n",
    "Y_test_t_h = to_categorical(Y_test)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), input_shape=(28, 28, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train_t_h, batch_size=64, epochs=5)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test_t_h)\n",
    "print('Test loss', test_loss)\n",
    "print('Test accuracy', test_acc)\n",
    "\n",
    "test_predictions = model.predict_classes(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_true = Y_test, y_pred = test_predictions)\n",
    "print(confusion_matrix)\n",
    "print(classification_report(y_true = Y_test, y_pred = test_predictions))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
